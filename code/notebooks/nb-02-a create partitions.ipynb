{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6328e5-0e69-466e-a2f8-8447561f7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ad8c2-baee-4f73-8046-7321f34d80c3",
   "metadata": {},
   "source": [
    "### 1. Get HPO-annotated image names (N=171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a733f1-930a-484f-b059-9a447b7ebea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have these images in the database:\n",
      "['22q11DSSlide150.png', 'KSSlide133.png', 'NSSlide6.png', 'WSSlide316.png']\n"
     ]
    }
   ],
   "source": [
    "hpo_terms_from_csv_files = []\n",
    "image_names = []\n",
    "for syndrome in ['22q11DS', 'Angelman', 'KS', 'NS', 'WS']:\n",
    "    df = pd.read_csv(pathlib.Path(pathlib.Path.cwd(), 'metadata', 'annotated-hpo-terms', '%s.csv'%syndrome))\n",
    "    hpo_terms_from_csv_files += df.keys()[2:-1].to_list()\n",
    "    image_names += df['image_name'].to_list()\n",
    "\n",
    "df = pd.read_csv(pathlib.Path(pathlib.Path.cwd(), 'metadata', 'facedet.csv'))\n",
    "\n",
    "print('I do not have these images in the database:')\n",
    "missing_images = [i for i in image_names if i not in df['image_name'].to_list()]\n",
    "print(missing_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38190f-a4a8-4725-9bc7-cdcb8b546e75",
   "metadata": {},
   "source": [
    "### 2. Seperate these samples from the main data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bed6b44a-7b68-4828-9e05-deef6157082a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>  (3544, 16)\n",
      "==>  (3373, 16)\n"
     ]
    }
   ],
   "source": [
    "testset_images = [image_name for image_name in image_names if image_name in df['image_name'].to_list()]\n",
    "testset_indices = [idx for idx, image_name in enumerate(df['image_name'].to_list()) if image_name in testset_images]\n",
    "\n",
    "print('==> ', df.shape)\n",
    "\n",
    "# HPO-annotated 171 images\n",
    "df_testset = df.iloc[testset_indices,:].reset_index(drop=True)\n",
    "n_testset = df_testset.shape[0]\n",
    "\n",
    "df = df.drop(index=testset_indices).reset_index(drop=True)\n",
    "print('==> ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d8b5e-9ae1-4ef6-b738-c268be36d83f",
   "metadata": {},
   "source": [
    "### 3. Get names of related images (any kinship relation--to be used to create partitions in cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80cf408-bbfd-45c5-95e1-9d5f84f8e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_txt = [f.split('Slide')[0] for f in df['image_name']]\n",
    "categories = np.unique(labels_txt)\n",
    "labels = np.array([np.argwhere(categories==labels_txt[i]).squeeze() for i in range(0, len(labels_txt))])\n",
    "image_names = np.array([f.replace('.png','') for f in df['image_name']])\n",
    "\n",
    "file1 = open(pathlib.Path(pathlib.Path.cwd(), 'metadata','related_samples.csv').as_posix(), 'r')\n",
    "lines = file1.readlines()\n",
    "related_samples = []\n",
    "for i in range(1, len(lines)):\n",
    "    related_samples.append(lines[i].replace('\\n','').replace(' ','').replace('\\'','').split(','))  \n",
    "\n",
    "\n",
    "# image_names\n",
    "# labels\n",
    "# groups\n",
    "groups = -np.ones(shape=(len(image_names),))\n",
    "\n",
    "for idx, sample in enumerate(related_samples):\n",
    "    \n",
    "    for item in sample:\n",
    "        #print(idx, sample, item)\n",
    "        ii = np.argwhere(image_names==item)\n",
    "        groups[ii] = idx\n",
    "        \n",
    "j = np.max(groups) + 1\n",
    "for idx in range(0, groups.shape[0]):\n",
    "    if groups[idx]==-1:\n",
    "        groups[idx] = j\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76650fb2-5563-4a96-ace2-9777ac198c6a",
   "metadata": {},
   "source": [
    "### 4. Create 5-folds (StratifiedGroupKFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd776d40-08a1-477f-8e6c-b1138c762007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2698 675\n",
      "[0.166, 0.125, 0.091, 0.036, 0.105, 0.063, 0.086, 0.031, 0.032, 0.069, 0.052]\n",
      "[0.161, 0.124, 0.093, 0.034, 0.104, 0.062, 0.089, 0.031, 0.03, 0.064, 0.056]\n",
      "\n",
      "\n",
      "1 2701 672\n",
      "[0.165, 0.126, 0.091, 0.036, 0.104, 0.063, 0.087, 0.031, 0.031, 0.067, 0.053]\n",
      "[0.164, 0.121, 0.094, 0.036, 0.106, 0.061, 0.088, 0.03, 0.031, 0.071, 0.051]\n",
      "\n",
      "\n",
      "2 2696 677\n",
      "[0.165, 0.124, 0.091, 0.036, 0.104, 0.063, 0.088, 0.031, 0.032, 0.068, 0.052]\n",
      "[0.165, 0.126, 0.093, 0.035, 0.106, 0.064, 0.084, 0.031, 0.028, 0.068, 0.056]\n",
      "\n",
      "\n",
      "3 2701 672\n",
      "[0.164, 0.124, 0.092, 0.036, 0.104, 0.063, 0.087, 0.031, 0.031, 0.068, 0.053]\n",
      "[0.168, 0.126, 0.089, 0.034, 0.104, 0.062, 0.085, 0.031, 0.033, 0.067, 0.051]\n",
      "\n",
      "\n",
      "4 2696 677\n",
      "[0.165, 0.124, 0.092, 0.035, 0.105, 0.062, 0.086, 0.031, 0.03, 0.068, 0.053]\n",
      "[0.167, 0.126, 0.087, 0.038, 0.102, 0.065, 0.089, 0.031, 0.034, 0.068, 0.05]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "sgkf.get_n_splits(image_names, labels, groups)\n",
    "\n",
    "folds = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sgkf.split(image_names, labels, groups)):\n",
    "    \n",
    "    print(i, len(train_index), len(test_index))\n",
    "    print( [round(sum(labels[train_index]==i)/labels[train_index].size, 3) for i in range(0, 11)] )\n",
    "    print( [round(sum(labels[test_index]==i)/labels[test_index].size, 3) for i in range(0, 11)] )\n",
    "    print('\\n')\n",
    "    \n",
    "    fold = []\n",
    "    for j in range(0, image_names.shape[0]):\n",
    "        if j in list(train_index):\n",
    "            fold.append('train')\n",
    "        elif j in list(test_index):\n",
    "            fold.append('val')\n",
    "\n",
    "    folds.append(fold)\n",
    "    \n",
    "df = pd.concat([df, pd.DataFrame({'fold-1':folds[0], 'fold-2':folds[1], 'fold-3':folds[2], 'fold-4':folds[3], 'fold-5':folds[4]})] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d627d373-d7db-49cc-aacf-ad1f6f18efec",
   "metadata": {},
   "source": [
    "### 5 .Combine both data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa023d62-3859-4727-8446-dd035254599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testset = pd.concat([df_testset, pd.DataFrame({'fold-1':n_testset*['test'], \n",
    "                                                  'fold-2':n_testset*['test'], \n",
    "                                                  'fold-3':n_testset*['test'], \n",
    "                                                  'fold-4':n_testset*['test'], \n",
    "                                                  'fold-5':n_testset*['test']})] , axis=1)\n",
    "\n",
    "df = pd.concat([df, df_testset], axis=0).reset_index(drop=True)\n",
    "df.to_csv(pathlib.Path(pathlib.Path.cwd(), 'metadata', 'partitions.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c477f-dd92-4bd8-b233-3b338059adf2",
   "metadata": {},
   "source": [
    "### 6. Check class distribution across folds (in stratified cross validation, we should preserve the original class distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a581784e-0a66-4213-9c07-8ee21dfcfac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['22q11DS', 'Angelman', 'BWS', 'CdLS', 'Down', 'KS', 'NS', 'PWS', 'RSTS1', 'Unaffected', 'WHS', 'WS']\n",
      "[0.166, 0.125, 0.091, 0.036, 0.105, 0.063, 0.086, 0.031, 0.032, 0.069, 0.052, 0.146] \t 2698\n",
      "[0.165, 0.126, 0.091, 0.036, 0.104, 0.063, 0.087, 0.031, 0.031, 0.067, 0.053, 0.147] \t 2701\n",
      "[0.165, 0.124, 0.091, 0.036, 0.104, 0.063, 0.088, 0.031, 0.032, 0.068, 0.052, 0.148] \t 2696\n",
      "[0.164, 0.124, 0.092, 0.036, 0.104, 0.063, 0.087, 0.031, 0.031, 0.068, 0.053, 0.147] \t 2701\n",
      "[0.165, 0.124, 0.092, 0.035, 0.105, 0.062, 0.086, 0.031, 0.03, 0.068, 0.053, 0.148] \t 2696\n",
      "\n",
      "[0.167, 0.129, 0.087, 0.034, 0.099, 0.069, 0.092, 0.029, 0.03, 0.064, 0.05, 0.149] \t 3544\n",
      "\n",
      "[0.199, 0.211, 0.0, 0.0, 0.0, 0.199, 0.199, 0.0, 0.0, 0.0, 0.0, 0.193] \t 171\n"
     ]
    }
   ],
   "source": [
    "categories = ['22q11DS', 'Angelman', 'BWS', 'CdLS', 'Down', 'KS', 'NS', 'PWS', 'RSTS1', 'Unaffected', 'WHS', 'WS']\n",
    "print(categories)\n",
    "\n",
    "for fold in ['fold-1','fold-2','fold-3','fold-4','fold-5']:\n",
    "    df = pd.read_csv(pathlib.Path(pathlib.Path.cwd(), 'metadata','partitions.csv'))\n",
    "    df = df[df[fold]=='train'].reset_index(drop=True)\n",
    "    \n",
    "    labels = [f.split('Slide')[0] for f in list(df['image_name']) ]\n",
    "    labels = np.array([np.argwhere(np.array(categories)==f).squeeze() for f in labels])\n",
    "    print([round(np.sum(labels==i)/len(labels), 3) for i in range(0, 12)], '\\t', len(labels))\n",
    "\n",
    "df = pd.read_csv(pathlib.Path(pathlib.Path.cwd(), 'metadata','partitions.csv'))\n",
    "labels = [f.split('Slide')[0] for f in list(df['image_name']) ]\n",
    "labels = np.array([np.argwhere(np.array(categories)==f).squeeze() for f in labels])\n",
    "print('')\n",
    "print([round(np.sum(labels==i)/len(labels), 3) for i in range(0, 12)], '\\t', len(labels))\n",
    "\n",
    "\n",
    "df = pd.read_csv(pathlib.Path(pathlib.Path.cwd(), 'metadata','partitions.csv'))\n",
    "df = df[df['fold-1']=='test'].reset_index(drop=True)\n",
    "labels = [f.split('Slide')[0] for f in list(df['image_name']) ]\n",
    "labels = np.array([np.argwhere(np.array(categories)==f).squeeze() for f in labels])\n",
    "print('')\n",
    "print([round(np.sum(labels==i)/len(labels), 3) for i in range(0, 12)], '\\t', len(labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
